<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"kjgggggg.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/public/search.xml"};
  </script>

  <meta name="description" content="pytorchå®ç°Transformer">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer pytorch">
<meta property="og:url" content="https://kjgggggg.github.io/2022/08/01/Transformer-pytorch/index.html">
<meta property="og:site_name" content="kjg&#39;s blog">
<meta property="og:description" content="pytorchå®ç°Transformer">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kjgggggg.github.io/2022/08/01/Transformer-pytorch/901659325530_.pic_%E5%89%AF%E6%9C%AC.png">
<meta property="article:published_time" content="2022-08-01T03:21:57.000Z">
<meta property="article:modified_time" content="2022-08-01T06:47:06.546Z">
<meta property="article:author" content="kjg">
<meta property="article:tag" content="deeplearning">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kjgggggg.github.io/2022/08/01/Transformer-pytorch/901659325530_.pic_%E5%89%AF%E6%9C%AC.png">

<link rel="canonical" href="https://kjgggggg.github.io/2022/08/01/Transformer-pytorch/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Transformer pytorch | kjg's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">kjg's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="æœç´¢..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://kjgggggg.github.io/2022/08/01/Transformer-pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/WechatIMG84.jpeg">
      <meta itemprop="name" content="kjg">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kjg's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Transformer pytorch
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>
              

              <time title="åˆ›å»ºæ—¶é—´ï¼š2022-08-01 11:21:57 / ä¿®æ”¹æ—¶é—´ï¼š14:47:06" itemprop="dateCreated datePublished" datetime="2022-08-01T11:21:57+08:00">2022-08-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deeplearning-pytorch/" itemprop="url" rel="index"><span itemprop="name">deeplearning pytorch</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="é˜…è¯»æ¬¡æ•°" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">pytorchå®ç°Transformer</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Transformeræ¦‚è§ˆ"><a href="#Transformeræ¦‚è§ˆ" class="headerlink" title="Transformeræ¦‚è§ˆ"></a>Transformeræ¦‚è§ˆ</h3><p><img src="/2022/08/01/Transformer-pytorch/901659325530_.pic_%E5%89%AF%E6%9C%AC.png" alt="901659325530_.pic"></p>
<h3 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ======================================</span></span><br><span class="line"><span class="comment"># === Pytorchæ‰‹å†™Transformerå®Œæ•´ä»£ç </span></span><br><span class="line"><span class="comment"># ======================================</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"></span><br><span class="line">device = <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"><span class="comment"># device = &#x27;cuda&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># transformer epochs</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œæˆ‘æ²¡æœ‰ç”¨ä»€ä¹ˆå¤§å‹çš„æ•°æ®é›†ï¼Œè€Œæ˜¯æ‰‹åŠ¨è¾“å…¥äº†ä¸¤å¯¹ä¸­æ–‡â†’è‹±è¯­çš„å¥å­</span></span><br><span class="line"><span class="comment"># è¿˜æœ‰æ¯ä¸ªå­—çš„ç´¢å¼•ä¹Ÿæ˜¯æˆ‘æ‰‹åŠ¨ç¡¬ç¼–ç ä¸Šå»çš„ï¼Œä¸»è¦æ˜¯ä¸ºäº†é™ä½ä»£ç é˜…è¯»éš¾åº¦</span></span><br><span class="line"><span class="comment"># S: Symbol that shows starting of decoding input</span></span><br><span class="line"><span class="comment"># E: Symbol that shows starting of decoding output</span></span><br><span class="line"><span class="comment"># P: Symbol that will fill in blank sequence if current batch data size is short than time steps</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒé›†</span></span><br><span class="line">sentences = [</span><br><span class="line">    <span class="comment"># ä¸­æ–‡å’Œè‹±è¯­çš„å•è¯ä¸ªæ•°ä¸è¦æ±‚ç›¸åŒ</span></span><br><span class="line">    <span class="comment"># enc_input                dec_input           dec_output</span></span><br><span class="line">    [<span class="string">&#x27;æˆ‘ æœ‰ ä¸€ ä¸ª å¥½ æœ‹ å‹ P&#x27;</span>, <span class="string">&#x27;S i have a good friend .&#x27;</span>, <span class="string">&#x27;i have a good friend . E&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;æˆ‘ æœ‰ é›¶ ä¸ª å¥³ æœ‹ å‹ P&#x27;</span>, <span class="string">&#x27;S i have zero girl friend .&#x27;</span>, <span class="string">&#x27;i have zero girl friend . E&#x27;</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•é›†ï¼ˆå¸Œæœ›transformerèƒ½è¾¾åˆ°çš„æ•ˆæœï¼‰</span></span><br><span class="line"><span class="comment"># è¾“å…¥ï¼š&quot;æˆ‘ æœ‰ ä¸€ ä¸ª å¥³ æœ‹ å‹&quot;</span></span><br><span class="line"><span class="comment"># è¾“å‡ºï¼š&quot;i have a girlfriend&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸­æ–‡å’Œè‹±è¯­çš„å•è¯è¦åˆ†å¼€å»ºç«‹è¯åº“</span></span><br><span class="line"><span class="comment"># Padding Should be Zero</span></span><br><span class="line">src_vocab = &#123;<span class="string">&#x27;P&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;æˆ‘&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;æœ‰&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;ä¸€&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;ä¸ª&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;å¥½&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;æœ‹&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;å‹&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;é›¶&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;å¥³&#x27;</span>: <span class="number">9</span>&#125;</span><br><span class="line">src_idx2word = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(src_vocab)&#125;</span><br><span class="line">src_vocab_size = <span class="built_in">len</span>(src_vocab)</span><br><span class="line"></span><br><span class="line">tgt_vocab = &#123;<span class="string">&#x27;P&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;i&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;have&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;a&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;good&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;friend&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;zero&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;girl&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;S&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;E&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;.&#x27;</span>: <span class="number">10</span>&#125;</span><br><span class="line">idx2word = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(tgt_vocab)&#125;</span><br><span class="line">tgt_vocab_size = <span class="built_in">len</span>(tgt_vocab)</span><br><span class="line"></span><br><span class="line">src_len = <span class="number">8</span>  <span class="comment"># ï¼ˆæºå¥å­çš„é•¿åº¦ï¼‰enc_input max sequence length</span></span><br><span class="line">tgt_len = <span class="number">7</span>  <span class="comment"># dec_input(=dec_output) max sequence length</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transformer Parameters</span></span><br><span class="line">d_model = <span class="number">512</span>  <span class="comment"># Embedding Size æ¯ä¸ªè¯è¢«åµŒå…¥æˆå‡ ç»´è¯å‘é‡</span></span><br><span class="line">d_ff = <span class="number">2048</span>  <span class="comment"># FeedForward dimension (ä¸¤æ¬¡çº¿æ€§å±‚ä¸­çš„éšè—å±‚ 512-&gt;2048-&gt;512ï¼Œçº¿æ€§å±‚æ˜¯ç”¨æ¥åšç‰¹å¾æå–çš„ï¼‰ï¼Œå½“ç„¶æœ€åä¼šå†æ¥ä¸€ä¸ªprojectionå±‚</span></span><br><span class="line">d_k = d_v = <span class="number">64</span>  <span class="comment"># dimension of K(=Q), Vï¼ˆQå’ŒKçš„ç»´åº¦éœ€è¦ç›¸åŒï¼Œè¿™é‡Œä¸ºäº†æ–¹ä¾¿è®©K=Vï¼‰</span></span><br><span class="line">n_layers = <span class="number">6</span>  <span class="comment"># number of Encoder of Decoder Layerï¼ˆBlockçš„ä¸ªæ•°ï¼‰</span></span><br><span class="line">n_heads = <span class="number">8</span>  <span class="comment"># number of heads in Multi-Head Attentionï¼ˆæœ‰å‡ ä¸ªå¤´ï¼‰</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ==============================================================================================</span></span><br><span class="line"><span class="comment"># æ•°æ®æ„å»º</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_data</span>(<span class="params">sentences</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;æŠŠå•è¯åºåˆ—è½¬æ¢ä¸ºæ•°å­—åºåˆ—&quot;&quot;&quot;</span></span><br><span class="line">    enc_inputs, dec_inputs, dec_outputs = [], [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences)):</span><br><span class="line">        enc_input = [[src_vocab[n] <span class="keyword">for</span> n <span class="keyword">in</span> sentences[i][<span class="number">0</span>].split()]]  <span class="comment"># [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]</span></span><br><span class="line">        dec_input = [[tgt_vocab[n] <span class="keyword">for</span> n <span class="keyword">in</span> sentences[i][<span class="number">1</span>].split()]]  <span class="comment"># [[6, 1, 2, 3, 4, 8], [6, 1, 2, 3, 5, 8]]</span></span><br><span class="line">        dec_output = [[tgt_vocab[n] <span class="keyword">for</span> n <span class="keyword">in</span> sentences[i][<span class="number">2</span>].split()]]  <span class="comment"># [[1, 2, 3, 4, 8, 7], [1, 2, 3, 5, 8, 7]]</span></span><br><span class="line"></span><br><span class="line">        enc_inputs.extend(enc_input) <span class="comment"># [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]</span></span><br><span class="line">        dec_inputs.extend(dec_input) <span class="comment"># [[6, 1, 2, 3, 4, 8], [6, 1, 2, 3, 5, 8]]</span></span><br><span class="line">        dec_outputs.extend(dec_output) <span class="comment"># [[1, 2, 3, 4, 8, 7], [1, 2, 3, 5, 8, 7]]</span></span><br><span class="line">        <span class="comment"># A = [1, 2, 3]</span></span><br><span class="line">        <span class="comment"># B = [[&#x27;a&#x27;, &#x27;b&#x27;]]</span></span><br><span class="line">        <span class="comment"># A.extend([4])</span></span><br><span class="line">        <span class="comment"># A.extend([5, 6])</span></span><br><span class="line">        <span class="comment"># B.extend([&#x27;c&#x27;, &#x27;d&#x27;])</span></span><br><span class="line">        <span class="comment"># B.extend([[&#x27;e&#x27;, &#x27;f&#x27;]])</span></span><br><span class="line">        <span class="comment"># print(A)</span></span><br><span class="line">        <span class="comment"># print(B)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># result:</span></span><br><span class="line">        <span class="comment"># [1, 2, 3, 4, 5, 6]</span></span><br><span class="line">        <span class="comment"># [[&#x27;a&#x27;, &#x27;b&#x27;], &#x27;c&#x27;, &#x27;d&#x27;, [&#x27;e&#x27;, &#x27;f&#x27;]]</span></span><br><span class="line">    <span class="keyword">return</span> torch.LongTensor(enc_inputs), torch.LongTensor(dec_inputs), torch.LongTensor(dec_outputs)</span><br><span class="line"></span><br><span class="line">enc_inputs, dec_inputs, dec_outputs = make_data(sentences)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(Data.Dataset):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;è‡ªå®šä¹‰DataLoader&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, enc_inputs, dec_inputs, dec_outputs</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDataSet, self).__init__()</span><br><span class="line">        self.enc_inputs = enc_inputs</span><br><span class="line">        self.dec_inputs = dec_inputs</span><br><span class="line">        self.dec_outputs = dec_outputs</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.enc_inputs.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># data.DataLoader</span></span><br><span class="line"><span class="comment"># datasetï¼šï¼ˆæ•°æ®ç±»å‹ datasetï¼‰</span></span><br><span class="line"><span class="comment"># batch_sizeï¼šï¼ˆæ•°æ®ç±»å‹ intï¼‰</span></span><br><span class="line"><span class="comment"># shuffleï¼šï¼ˆæ•°æ®ç±»å‹ boolï¼‰æ´—ç‰Œã€‚é»˜è®¤è®¾ç½®ä¸ºFalseã€‚åœ¨æ¯æ¬¡è¿­ä»£è®­ç»ƒæ—¶æ˜¯å¦å°†æ•°æ®æ´—ç‰Œï¼Œé»˜è®¤è®¾ç½®æ˜¯Falseã€‚å°†è¾“å…¥æ•°æ®çš„é¡ºåºæ‰“ä¹±ï¼Œæ˜¯ä¸ºäº†ä½¿æ•°æ®æ›´æœ‰ç‹¬ç«‹æ€§ï¼Œä½†å¦‚æœæ•°æ®æ˜¯æœ‰åºåˆ—ç‰¹å¾çš„ï¼Œå°±ä¸è¦è®¾ç½®æˆTrueäº†ã€‚</span></span><br><span class="line"><span class="comment"># batch_samplerï¼šï¼ˆæ•°æ®ç±»å‹ Samplerï¼‰</span></span><br><span class="line"><span class="comment"># samplerï¼šï¼ˆæ•°æ®ç±»å‹ Samplerï¼‰</span></span><br><span class="line"><span class="comment"># num_workersï¼šï¼ˆæ•°æ®ç±»å‹ Intï¼‰</span></span><br><span class="line"><span class="comment"># pin_memoryï¼šï¼ˆæ•°æ®ç±»å‹ boolï¼‰</span></span><br><span class="line"><span class="comment"># drop_lastï¼šï¼ˆæ•°æ®ç±»å‹ boolï¼‰</span></span><br><span class="line"><span class="comment"># timeoutï¼šï¼ˆæ•°æ®ç±»å‹ numericï¼‰</span></span><br><span class="line"></span><br><span class="line">loader = Data.DataLoader(MyDataSet(enc_inputs, dec_inputs, dec_outputs), <span class="number">2</span>, <span class="literal">True</span>)  <span class="comment"># 2ä¸ªbatchæ˜¯ä¸¤å¥è¯</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ====================================================================================================</span></span><br><span class="line"><span class="comment"># Transformeræ¨¡å‹(çœå»äº†Embeddingå±‚ï¼Œå› ä¸ºæˆ‘ä»¬ä¹‹å‰è‡ªå·±å®šä¹‰è¿‡src_vocabå’Œtgt_vocab)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout=<span class="number">0.1</span>, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x: [seq_len, batch_size, d_model]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = x + self.pe[:x.size(<span class="number">0</span>), :]</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_pad_mask</span>(<span class="params">seq_q, seq_k</span>):<span class="comment">#åºåˆ—ï¼ˆå¥å­ï¼‰ï¼Œä¸å¤Ÿé•¿æ—¶ç”¨padå¡«è¡¥ã€‚ä¸ºäº†è®©padçš„ä½ç½®ä¸å‚ä¸æƒé‡è®¡ç®—ï¼Œå°†pad=0çš„ä½ç½®è®¾ä¸ºtrue</span></span><br><span class="line">    <span class="comment"># pad maskçš„ä½œç”¨ï¼šåœ¨å¯¹valueå‘é‡åŠ æƒå¹³å‡çš„æ—¶å€™ï¼Œå¯ä»¥è®©padå¯¹åº”çš„alpha_ij=0ï¼Œè¿™æ ·æ³¨æ„åŠ›å°±ä¸ä¼šè€ƒè™‘åˆ°padå‘é‡</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;è¿™é‡Œçš„q,kè¡¨ç¤ºçš„æ˜¯ä¸¤ä¸ªåºåˆ—ï¼ˆè·Ÿæ³¨æ„åŠ›æœºåˆ¶çš„q,kæ²¡æœ‰å…³ç³»ï¼‰ï¼Œä¾‹å¦‚encoder_inputs (x1,x2,..xm)å’Œencoder_inputs (x1,x2..xm)</span></span><br><span class="line"><span class="string">    encoderå’Œdecoderéƒ½å¯èƒ½è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œæ‰€ä»¥seq_lenè§†æƒ…å†µè€Œå®š</span></span><br><span class="line"><span class="string">    seq_q: [batch_size, seq_len]</span></span><br><span class="line"><span class="string">    seq_k: [batch_size, seq_len]</span></span><br><span class="line"><span class="string">    seq_len could be src_len or it could be tgt_len</span></span><br><span class="line"><span class="string">    seq_len in seq_q and seq_len in seq_k maybe not equal</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batch_size, len_q = seq_q.size()  <span class="comment"># è¿™ä¸ªseq_qåªæ˜¯ç”¨æ¥expandç»´åº¦çš„</span></span><br><span class="line">    batch_size, len_k = seq_k.size()</span><br><span class="line">    <span class="comment"># eq(zero) is PAD token</span></span><br><span class="line">    <span class="comment"># ä¾‹å¦‚:seq_k = [[1,2,3,4,0], [1,2,3,5,0]]</span></span><br><span class="line">    <span class="comment"># åˆ¤æ–­æ˜¯å¦ä¸º0ï¼Œæ˜¯0åˆ™ä¸ºTrueï¼ŒTrueåˆ™maskedï¼Œå¹¶æ‰©ä¸€ä¸ªç»´åº¦ã€‚# ä¾‹å¦‚:seq_k = [[1,2,3,4,0], [1,2,3,5,0]]ï¼Œ--&gt;[[F,F,F,F,T]][F,F,F,F,T]</span></span><br><span class="line">    pad_attn_mask = seq_k.data.eq(<span class="number">0</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># [batch_size, 1, len_k]</span></span><br><span class="line">    <span class="keyword">return</span> pad_attn_mask.expand(batch_size, len_q, len_k)  <span class="comment"># [batch_size, len_q, len_k] æ„æˆä¸€ä¸ªç«‹æ–¹ä½“(batch_sizeä¸ªè¿™æ ·çš„çŸ©é˜µ)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_subsequence_mask</span>(<span class="params">seq</span>):<span class="comment">#ä¸€æ¬¡åªç¿»è¯‘ä¸€ä¸ªè¯</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;å»ºè®®æ‰“å°å‡ºæ¥çœ‹çœ‹æ˜¯ä»€ä¹ˆçš„è¾“å‡ºï¼ˆä¸€ç›®äº†ç„¶ï¼‰</span></span><br><span class="line"><span class="string">    seq: [batch_size, tgt_len]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    attn_shape = [seq.size(<span class="number">0</span>), seq.size(<span class="number">1</span>), seq.size(<span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># attn_shape: [batch_size, tgt_len, tgt_len]</span></span><br><span class="line">    subsequence_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>)  <span class="comment"># ç”Ÿæˆä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µ</span></span><br><span class="line">    subsequence_mask = torch.from_numpy(subsequence_mask).byte()</span><br><span class="line">    <span class="keyword">return</span> subsequence_mask  <span class="comment"># [batch_size, tgt_len, tgt_len]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ==========================================================================================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ScaledDotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ScaledDotProductAttention, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, attn_mask</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Q: [batch_size, n_heads, len_q, d_k]</span></span><br><span class="line"><span class="string">        K: [batch_size, n_heads, len_k, d_k]</span></span><br><span class="line"><span class="string">        V: [batch_size, n_heads, len_v(=len_k), d_v]</span></span><br><span class="line"><span class="string">        attn_mask: [batch_size, n_heads, seq_len, seq_len]</span></span><br><span class="line"><span class="string">        è¯´æ˜ï¼šåœ¨encoder-decoderçš„Attentionå±‚ä¸­len_q(q1,..qt)å’Œlen_k(k1,...km)å¯èƒ½ä¸åŒ</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        scores = torch.matmul(Q, K.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) / np.sqrt(d_k)  <span class="comment"># scores : [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        <span class="comment"># maskçŸ©é˜µå¡«å……scoresï¼ˆç”¨-1e9å¡«å……scoresä¸­ä¸attn_maskä¸­å€¼ä¸º1ä½ç½®ç›¸å¯¹åº”çš„å…ƒç´ ï¼‰</span></span><br><span class="line">        scores.masked_fill_(attn_mask, -<span class="number">1e9</span>)  <span class="comment"># Fills elements of self tensor with value where mask is True.</span></span><br><span class="line"></span><br><span class="line">        attn = nn.Softmax(dim=-<span class="number">1</span>)(scores)  <span class="comment"># å¯¹æœ€åä¸€ä¸ªç»´åº¦(v)åšsoftmax</span></span><br><span class="line">        <span class="comment"># scores : [batch_size, n_heads, len_q, len_k] * V: [batch_size, n_heads, len_v(=len_k), d_v]</span></span><br><span class="line">        context = torch.matmul(attn, V)  <span class="comment"># context: [batch_size, n_heads, len_q, d_v]</span></span><br><span class="line">        <span class="comment"># contextï¼š[[z1,z2,...],[...]]å‘é‡, attnæ³¨æ„åŠ›ç¨€ç–çŸ©é˜µï¼ˆç”¨äºå¯è§†åŒ–çš„ï¼‰</span></span><br><span class="line">        <span class="keyword">return</span> context, attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/deeplearning/" rel="tag"># deeplearning</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
              <a href="/tags/pytorch/" rel="tag"># pytorch</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/07/31/Self-Attention/" rel="prev" title="Self Attention">
      <i class="fa fa-chevron-left"></i> Self Attention
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Transformer%E6%A6%82%E8%A7%88"><span class="nav-number">1.</span> <span class="nav-text">Transformeræ¦‚è§ˆ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81"><span class="nav-number">2.</span> <span class="nav-text">ä»£ç </span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="kjg"
      src="/images/WechatIMG84.jpeg">
  <p class="site-author-name" itemprop="name">kjg</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/kjgggggg" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;kjgggggg" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/651373472@qq.com" title="E-Mail â†’ 651373472@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
</div>

<span style="text-align:center;display:block;">
<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span <div>wmr</div> </span>
</span>

        
<span style="text-align:center;display:block;">
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        æœ¬ç«™æ€»è®¿é—®äººæ•°ï¼š
      </span>
      <span class="site-uv" title="æ€»è®¿å®¢é‡">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider"></span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        æœ¬ç«™æ€»è®¿é—®é‡ï¼š 
      </span>
      <span class="site-pv" title="æ€»è®¿é—®é‡">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
</span>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '16px',
  right: '28px',
  left: 'unset',
  time: '0.3s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: 'ğŸŒ“',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
